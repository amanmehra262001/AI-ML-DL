{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e452ed3b-e6cf-4a39-884d-afb91a995565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This model is created for easy translation from english to hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb03d9ed-ddbb-42ad-bbf7-f8aadd88035a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:35:48.572745: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-25 18:35:48.632930: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-25 18:35:49.723814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# tensorflow and keras\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28ce5273-543c-4cf2-9ce4-11d953ed8346",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91caf821-be73-4f26-96f4-6245156840ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Hindi_English_Truncated_Corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97957398-1fd3-45aa-9c96-f3e9f7eb70a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35494</th>\n",
       "      <td>The older sons joined their father 's business...</td>\n",
       "      <td>उनके बड़े पुत्र फ्रांस में अपने पिता की व्यावस...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35495</th>\n",
       "      <td>Best collection of some special hindi poetry.</td>\n",
       "      <td>हिन्दी काव्य के उत्कृष्ट रचनाओं का उत्तम संग्रह</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35496</th>\n",
       "      <td>And it took about a year.</td>\n",
       "      <td>इसमें तकरीबन एक साल लगा ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35497</th>\n",
       "      <td>Put yourself in the shoes</td>\n",
       "      <td>अब आप एक अमेरिकेन सेनिक की जगह से सोची ये</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35498</th>\n",
       "      <td>The “”Great Cricketer“”, W G Grace, made his f...</td>\n",
       "      <td>डब्लू जी ग्रेस (W G Grace)ने १८६५ में अपना लंब...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 english  \\\n",
       "0      politicians do not have permission to do what ...   \n",
       "1             I'd like to tell you about one such child,   \n",
       "2      This percentage is even greater than the perce...   \n",
       "3      what we really mean is that they're bad at not...   \n",
       "4      .The ending portion of these Vedas is called U...   \n",
       "...                                                  ...   \n",
       "35494  The older sons joined their father 's business...   \n",
       "35495      Best collection of some special hindi poetry.   \n",
       "35496                          And it took about a year.   \n",
       "35497                          Put yourself in the shoes   \n",
       "35498  The “”Great Cricketer“”, W G Grace, made his f...   \n",
       "\n",
       "                                                   hindi  \n",
       "0      राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1      मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2       यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3         हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4            इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
       "...                                                  ...  \n",
       "35494  उनके बड़े पुत्र फ्रांस में अपने पिता की व्यावस...  \n",
       "35495    हिन्दी काव्य के उत्कृष्ट रचनाओं का उत्तम संग्रह  \n",
       "35496                          इसमें तकरीबन एक साल लगा ।  \n",
       "35497          अब आप एक अमेरिकेन सेनिक की जगह से सोची ये  \n",
       "35498  डब्लू जी ग्रेस (W G Grace)ने १८६५ में अपना लंब...  \n",
       "\n",
       "[35499 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns='source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd30871c-3ba4-4e45-82b4-2519884afff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source     0\n",
       "english    0\n",
       "hindi      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13fb9bf-97cd-4421-a8a1-e94c774a04b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['hindi'] = df['hindi'].astype(str)\n",
    "df['english'] = df['english'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb7e25f-fb10-414f-85b9-3d1dd78ed281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['hindi'] = df['hindi'].str.strip()  # Hindi has no capital letters\n",
    "df['english'] = df['english'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe2bc1e-9094-4423-af33-94f77c806598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29bd357b-d160-412b-bfde-3d7eb88ba408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df[~df['english'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "306951e4-477a-43ce-8532-253761d92839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "df['english']=df['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df['hindi']=df['hindi'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386d4141-0de9-4132-8392-273c1cf4d912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "df['english']=df['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df['hindi']=df['hindi'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68aab33c-ec8a-4a2e-ad74-d04fd63fb701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "df['english']=df['english'].apply(lambda x: x.translate(remove_digits))\n",
    "df['hindi']=df['hindi'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "df['hindi']=df['hindi'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "df['english']=df['english'].apply(lambda x: x.strip())\n",
    "df['hindi']=df['hindi'].apply(lambda x: x.strip())\n",
    "df['english']=df['english'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "df['hindi']=df['hindi'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b226b132-92e5-4877-b263-03b680d1c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "df['hindi'] = df['hindi'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a6106c-94a8-412e-8eb8-6b3f596e1a00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in df['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in df['hindi']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b255ec-7dcf-4bb5-9615-60a021b7ca78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>id like to tell you about one such child</td>\n",
       "      <td>START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>this percentage is even greater than the perce...</td>\n",
       "      <td>START_ यह प्रतिशत भारत में हिन्दुओं प्रतिशत से...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that theyre bad at not ...</td>\n",
       "      <td>START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>the ending portion of these vedas is called up...</td>\n",
       "      <td>START_ इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35494</th>\n",
       "      <td>tides</td>\n",
       "      <td>the older sons joined their father s business ...</td>\n",
       "      <td>START_ उनके बड़े पुत्र फ्रांस में अपने पिता की...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35495</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>best collection of some special hindi poetry</td>\n",
       "      <td>START_ हिन्दी काव्य के उत्कृष्ट रचनाओं का उत्त...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35496</th>\n",
       "      <td>ted</td>\n",
       "      <td>and it took about a year</td>\n",
       "      <td>START_ इसमें तकरीबन एक साल लगा । _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35497</th>\n",
       "      <td>ted</td>\n",
       "      <td>put yourself in the shoes</td>\n",
       "      <td>START_ अब आप एक अमेरिकेन सेनिक की जगह से सोची ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35498</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>the “”great cricketer“” w g grace made his fir...</td>\n",
       "      <td>START_ डब्लू जी ग्रेस W G Graceने में अपना लंब...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34906 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source                                            english  \\\n",
       "0            ted  politicians do not have permission to do what ...   \n",
       "1            ted           id like to tell you about one such child   \n",
       "2      indic2012  this percentage is even greater than the perce...   \n",
       "3            ted  what we really mean is that theyre bad at not ...   \n",
       "4      indic2012  the ending portion of these vedas is called up...   \n",
       "...          ...                                                ...   \n",
       "35494      tides  the older sons joined their father s business ...   \n",
       "35495  indic2012       best collection of some special hindi poetry   \n",
       "35496        ted                           and it took about a year   \n",
       "35497        ted                          put yourself in the shoes   \n",
       "35498  indic2012  the “”great cricketer“” w g grace made his fir...   \n",
       "\n",
       "                                                   hindi  \n",
       "0      START_ राजनीतिज्ञों के पास जो कार्य करना चाहिए...  \n",
       "1      START_ मई आपको ऐसे ही एक बच्चे के बारे में बता...  \n",
       "2      START_ यह प्रतिशत भारत में हिन्दुओं प्रतिशत से...  \n",
       "3      START_ हम ये नहीं कहना चाहते कि वो ध्यान नहीं ...  \n",
       "4      START_ इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता...  \n",
       "...                                                  ...  \n",
       "35494  START_ उनके बड़े पुत्र फ्रांस में अपने पिता की...  \n",
       "35495  START_ हिन्दी काव्य के उत्कृष्ट रचनाओं का उत्त...  \n",
       "35496              START_ इसमें तकरीबन एक साल लगा । _END  \n",
       "35497  START_ अब आप एक अमेरिकेन सेनिक की जगह से सोची ...  \n",
       "35498  START_ डब्लू जी ग्रेस W G Graceने में अपना लंब...  \n",
       "\n",
       "[34906 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e3b29f-86fd-4a48-868f-baa148a1987d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36798, 44493)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words), len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5f8d240-0550-4f99-8cc1-b1a27bcb5f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['length_eng_sentence']=df['english'].apply(lambda x:len(x.split(\" \")))\n",
    "df['length_hin_sentence']=df['hindi'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecaae549-3435-425f-bfc3-3731a503055c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df[df['length_eng_sentence']<=20]\n",
    "df=df[df['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7add0f22-c1cc-4b40-afa4-dd89ffa41575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23095, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01fb80b0-9019-4ba9-915d-5a80c501cf2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(df['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(df['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44f69138-f329-441f-b82c-ee818c427190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length_src=max(df['length_hin_sentence'])\n",
    "max_length_tar=max(df['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab5592fc-ef2d-4847-b287-0c2e9306b41a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36798, 44493)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c0ddbc8-9f10-439a-bcba-e0c26792291e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens += 1 #for zero padding\n",
    "num_decoder_tokens += 1 #for zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c2d3051-1d71-4fa7-b4b1-1894bfe4eef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58e9b01b-9b0a-4e07-a195-041e30b14d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd4f7d21-3bbd-43e3-8105-62fbb43f9452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33449</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>upto year pakistans economy had been increasin...</td>\n",
       "      <td>START_ सन् तक पाकिस्तान की अर्थव्यवस्था प्रतिश...</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21778</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>in uttar pradesh maximum lok sabha members are...</td>\n",
       "      <td>START_ उत्तर प्रदेश से सर्वाधिक लोक सभा व राज्...</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16223</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>ramrajya become idol</td>\n",
       "      <td>START_ रामराज्य एक आदर्श बन गया। _END</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29317</th>\n",
       "      <td>ted</td>\n",
       "      <td>its that reeeeeeeeach out the physical contortion</td>\n",
       "      <td>START_ यह पसारना हैं शारीरिक विकृति _END</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33392</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>on this day for worship of yama deepak is infl...</td>\n",
       "      <td>START_ इस दिन यम पूजा हेतु दीपक जलाए जाते हैं।...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31615</th>\n",
       "      <td>ted</td>\n",
       "      <td>that makes us beautiful</td>\n",
       "      <td>START_ जो हमें सुन्दर बनाती हैं _END</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21247</th>\n",
       "      <td>tides</td>\n",
       "      <td>it takes seconds for the outgoing blood to ret...</td>\n",
       "      <td>START_ हृदय से बाहर निकले रक़्त को वापस आने मे...</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33773</th>\n",
       "      <td>ted</td>\n",
       "      <td>he said “do you know theres a solarelectrified...</td>\n",
       "      <td>START_ उसने कहा “आपको पता है कि सियरा ल्योन मे...</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>ted</td>\n",
       "      <td>if i spin this pulley the small ones going to ...</td>\n",
       "      <td>START_ अगर मैं इस चक्की को घुमाऊं तो छोटा वाला...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32905</th>\n",
       "      <td>ted</td>\n",
       "      <td>can stand out in the way that these things have</td>\n",
       "      <td>START_ यहाँ मशहूर हो सकते हैं। _END</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source                                            english  \\\n",
       "33449  indic2012  upto year pakistans economy had been increasin...   \n",
       "21778  indic2012  in uttar pradesh maximum lok sabha members are...   \n",
       "16223  indic2012                               ramrajya become idol   \n",
       "29317        ted  its that reeeeeeeeach out the physical contortion   \n",
       "33392  indic2012  on this day for worship of yama deepak is infl...   \n",
       "31615        ted                            that makes us beautiful   \n",
       "21247      tides  it takes seconds for the outgoing blood to ret...   \n",
       "33773        ted  he said “do you know theres a solarelectrified...   \n",
       "338          ted  if i spin this pulley the small ones going to ...   \n",
       "32905        ted    can stand out in the way that these things have   \n",
       "\n",
       "                                                   hindi  length_eng_sentence  \\\n",
       "33449  START_ सन् तक पाकिस्तान की अर्थव्यवस्था प्रतिश...                    8   \n",
       "21778  START_ उत्तर प्रदेश से सर्वाधिक लोक सभा व राज्...                   13   \n",
       "16223              START_ रामराज्य एक आदर्श बन गया। _END                    3   \n",
       "29317           START_ यह पसारना हैं शारीरिक विकृति _END                    7   \n",
       "33392  START_ इस दिन यम पूजा हेतु दीपक जलाए जाते हैं।...                   10   \n",
       "31615               START_ जो हमें सुन्दर बनाती हैं _END                    4   \n",
       "21247  START_ हृदय से बाहर निकले रक़्त को वापस आने मे...                   12   \n",
       "33773  START_ उसने कहा “आपको पता है कि सियरा ल्योन मे...                   12   \n",
       "338    START_ अगर मैं इस चक्की को घुमाऊं तो छोटा वाला...                   13   \n",
       "32905                START_ यहाँ मशहूर हो सकते हैं। _END                   10   \n",
       "\n",
       "       length_hin_sentence  \n",
       "33449                   16  \n",
       "21778                   16  \n",
       "16223                    7  \n",
       "29317                    7  \n",
       "33392                   11  \n",
       "31615                    7  \n",
       "21247                   16  \n",
       "33773                   16  \n",
       "338                     14  \n",
       "32905                    7  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67dd5266-4cf8-4648-a62d-ee8f8747ea73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18476,), (4619,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['english'], df['hindi'], test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c8c94fc-b23c-4e9c-800c-70d0ad1757ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's save this data\n",
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc6bed1e-b6d2-4527-8ed7-f98a485065c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04d1be9c-d6e4-448d-accf-c9bd1b8272fa",
   "metadata": {},
   "source": [
    "## Encoder Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a2d616f-c5c1-4caf-bab8-e3f376a856a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18c36ce4-fcab-44f3-8438-6d757f1be3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,)) # Defines an input layer for the encoder. The Input function is from the Keras API, and shape=(None,) specifies that the input sequence length can vary (indicated by None) and the dimensionality of each input element is unspecified (to be determined later).\n",
    "enc_emb =  Embedding(num_encoder_tokens, embedding_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(embedding_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39aebd-8a9e-40b5-9e7f-6d236e53599a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23da371e-627c-40e6-b851-df81187611fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, embedding_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we can use them in inference.\n",
    "decoder_lstm = LSTM(embedding_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4958fc5-2dab-4622-8ad8-50caaeb8c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e06270cb-4e60-475b-8e9a-48188032055f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, None, 100)    3679900     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 100)    4449500     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 100),        80400       ['embedding_2[0][0]']            \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 100),  80400       ['embedding_3[0][0]',            \n",
      "                                 (None, 100),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 100)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 44495)  4493995     ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,784,195\n",
      "Trainable params: 12,784,195\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6feb648d-efb0-4543-ac40-76865e3a3d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fad9df4-83cd-41c5-b07e-4606c79c43d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16712/2108290721.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:38:19.162486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - ETA: 0s - loss: 8.3075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:45:07.096848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 467s 3s/step - loss: 8.3075 - val_loss: 7.2728\n",
      "Epoch 2/50\n",
      "144/144 [==============================] - 458s 3s/step - loss: 7.1542 - val_loss: 7.1211\n",
      "Epoch 3/50\n",
      "144/144 [==============================] - 456s 3s/step - loss: 7.0347 - val_loss: 7.0505\n",
      "Epoch 4/50\n",
      "144/144 [==============================] - 457s 3s/step - loss: 6.9701 - val_loss: 7.0162\n",
      "Epoch 5/50\n",
      "144/144 [==============================] - 457s 3s/step - loss: 6.9339 - val_loss: 6.9934\n",
      "Epoch 6/50\n",
      "144/144 [==============================] - 457s 3s/step - loss: 6.9081 - val_loss: 6.9788\n",
      "Epoch 7/50\n",
      "144/144 [==============================] - 473s 3s/step - loss: 6.8853 - val_loss: 6.9640\n",
      "Epoch 8/50\n",
      "144/144 [==============================] - 456s 3s/step - loss: 6.8674 - val_loss: 6.9528\n",
      "Epoch 9/50\n",
      "144/144 [==============================] - 464s 3s/step - loss: 6.8521 - val_loss: 6.9404\n",
      "Epoch 10/50\n",
      "144/144 [==============================] - 480s 3s/step - loss: 6.8365 - val_loss: 6.9325\n",
      "Epoch 11/50\n",
      "144/144 [==============================] - 479s 3s/step - loss: 6.8236 - val_loss: 6.9235\n",
      "Epoch 12/50\n",
      "144/144 [==============================] - 473s 3s/step - loss: 6.8119 - val_loss: 6.9158\n",
      "Epoch 13/50\n",
      "144/144 [==============================] - 460s 3s/step - loss: 6.7989 - val_loss: 6.9077\n",
      "Epoch 14/50\n",
      "144/144 [==============================] - 458s 3s/step - loss: 6.7896 - val_loss: 6.9023\n",
      "Epoch 15/50\n",
      "144/144 [==============================] - 458s 3s/step - loss: 6.7793 - val_loss: 6.8974\n",
      "Epoch 16/50\n",
      "144/144 [==============================] - 456s 3s/step - loss: 6.7696 - val_loss: 6.8920\n",
      "Epoch 17/50\n",
      "144/144 [==============================] - 454s 3s/step - loss: 6.7592 - val_loss: 6.8890\n",
      "Epoch 18/50\n",
      "144/144 [==============================] - 452s 3s/step - loss: 6.7489 - val_loss: 6.8835\n",
      "Epoch 19/50\n",
      "144/144 [==============================] - 453s 3s/step - loss: 6.7379 - val_loss: 6.8839\n",
      "Epoch 20/50\n",
      "144/144 [==============================] - 452s 3s/step - loss: 6.7271 - val_loss: 6.8591\n",
      "Epoch 21/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.7144 - val_loss: 6.8539\n",
      "Epoch 22/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.6990 - val_loss: 6.8388\n",
      "Epoch 23/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.6787 - val_loss: 6.8256\n",
      "Epoch 24/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.6537 - val_loss: 6.7929\n",
      "Epoch 25/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.6238 - val_loss: 6.7670\n",
      "Epoch 26/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.5926 - val_loss: 6.7402\n",
      "Epoch 27/50\n",
      "144/144 [==============================] - 449s 3s/step - loss: 6.5619 - val_loss: 6.7188\n",
      "Epoch 28/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.5318 - val_loss: 6.6960\n",
      "Epoch 29/50\n",
      "144/144 [==============================] - 449s 3s/step - loss: 6.5018 - val_loss: 6.6844\n",
      "Epoch 30/50\n",
      "144/144 [==============================] - 449s 3s/step - loss: 6.4735 - val_loss: 6.6664\n",
      "Epoch 31/50\n",
      "144/144 [==============================] - 449s 3s/step - loss: 6.4459 - val_loss: 6.6369\n",
      "Epoch 32/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.4203 - val_loss: 6.6207\n",
      "Epoch 33/50\n",
      "144/144 [==============================] - 451s 3s/step - loss: 6.3950 - val_loss: 6.6081\n",
      "Epoch 34/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.3709 - val_loss: 6.5870\n",
      "Epoch 35/50\n",
      "144/144 [==============================] - 452s 3s/step - loss: 6.3473 - val_loss: 6.5693\n",
      "Epoch 36/50\n",
      "144/144 [==============================] - 451s 3s/step - loss: 6.3237 - val_loss: 6.5760\n",
      "Epoch 37/50\n",
      "144/144 [==============================] - 451s 3s/step - loss: 6.3008 - val_loss: 6.5536\n",
      "Epoch 38/50\n",
      "144/144 [==============================] - 452s 3s/step - loss: 6.2776 - val_loss: 6.5369\n",
      "Epoch 39/50\n",
      "144/144 [==============================] - 451s 3s/step - loss: 6.2541 - val_loss: 6.5353\n",
      "Epoch 40/50\n",
      "144/144 [==============================] - 452s 3s/step - loss: 6.2332 - val_loss: 6.5120\n",
      "Epoch 41/50\n",
      "144/144 [==============================] - 451s 3s/step - loss: 6.2106 - val_loss: 6.5218\n",
      "Epoch 42/50\n",
      "144/144 [==============================] - 450s 3s/step - loss: 6.1909 - val_loss: 6.5128\n",
      "Epoch 43/50\n",
      "144/144 [==============================] - 451s 3s/step - loss: 6.1708 - val_loss: 6.4916\n",
      "Epoch 44/50\n",
      "144/144 [==============================] - 452s 3s/step - loss: 6.1505 - val_loss: 6.4801\n",
      "Epoch 45/50\n",
      "144/144 [==============================] - 449s 3s/step - loss: 6.1325 - val_loss: 6.4795\n",
      "Epoch 46/50\n",
      "144/144 [==============================] - 448s 3s/step - loss: 6.1132 - val_loss: 6.4647\n",
      "Epoch 47/50\n",
      "144/144 [==============================] - 449s 3s/step - loss: 6.0954 - val_loss: 6.4667\n",
      "Epoch 48/50\n",
      "144/144 [==============================] - 449s 3s/step - loss: 6.0758 - val_loss: 6.4679\n",
      "Epoch 49/50\n",
      "144/144 [==============================] - 449s 3s/step - loss: 6.0608 - val_loss: 6.4465\n",
      "Epoch 50/50\n",
      "144/144 [==============================] - 448s 3s/step - loss: 6.0427 - val_loss: 6.4397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc3af50c190>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "695070b4-40d2-40eb-9edc-9141ebb4a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2524846f-d85c-4f3c-9171-493606aeb73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(embedding_dim,))\n",
    "decoder_state_input_c = Input(shape=(embedding_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08216571-5541-46c6-96aa-a042ee55a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb169767-b964-480e-ac88-7d24b45a18e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "294a8a49-2fdb-417d-bd0d-3de69c335fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Input English sentence: we see it in supermarkets on book covers\n",
      "Actual Hindi Translation:  हमने यह पुस्तक कवर पर सुपरमार्केट में देख़ा हैं। \n",
      "Predicted Hindi Translation:  हम एक एक एक एक एक एक एक एक भी भी भी \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8340cd00-977f-4937-aa16-f41a759c4511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Input English sentence: and gain a better understanding of our landscape\n",
      "Actual Hindi Translation:  और हमारे भुदेश्य की एक बेहतर समझ हासिल कर सकते हैं \n",
      "Predicted Hindi Translation:  और और हम एक एक एक एक एक एक एक भी भी भी \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9eb49c-46c7-43ed-9060-e971958abdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictoins are somewhat inaccurate maybe because of decreased size of dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
